# Point-Cloud-ML: Semantic Segmentation of Urban Roadways
![full lidar image](https://github.com/user-attachments/assets/1af9ccb9-af3e-482f-843b-407d47522fa2)

## Project Overview

![lidar base image](https://github.com/user-attachments/assets/830f7795-0a7f-4f72-b1e2-decd330389b3)

The **Point-Cloud-ML** project focuses on semantic segmentation of urban roadways using 3D point cloud data. Point cloud data, typically generated by LiDAR sensors, captures precise 3D information about objects and their surroundings. This project specifically uses the **Toronto-3D LiDAR dataset**, containing millions of points representing the city of Toronto, to segment various urban features such as buildings, roads, poles, and vehicles.

The primary objective is to develop a robust machine learning model capable of classifying each point within the dataset into meaningful categories. By leveraging the **PointNet architecture**, which is uniquely designed to handle unordered point cloud data, the project addresses the challenge of extracting useful patterns from complex 3D data.

### Key Goals:
- **Semantic Segmentation**: Classify individual points into different object types (e.g., buildings, roads, cars, vegetation).
- **Model Generalization**: Ensure the model can generalize well to unseen areas in urban roadways.
- **Efficiency**: Optimize the architecture for effective and efficient processing of large-scale point cloud data.

In this project, PointNet is used due to its capacity to handle raw point clouds directly, without the need for voxelization or meshing, which makes it particularly suited for large-scale datasets like **Toronto-3D**.

The model architecture has been adapted to focus on urban roadways, which consist of complex arrangements of static and dynamic objects. By performing point-wise classification, the trained model outputs segmentation masks that can highlight key urban infrastructure components, making it applicable to various real-world scenarios like autonomous driving, city planning, and traffic management.

## Dataset

![labeled lidar image](https://github.com/user-attachments/assets/5d1c2f81-c9d3-41f7-9755-56d3f4fba45d)

The **Toronto-3D** dataset is a large-scale urban outdoor point cloud dataset acquired in Toronto, Canada, using an MLS (Mobile Laser Scanning) system. It contains approximately 78.3 million points, covering 1 km of urban roadways. The dataset's approximate location is `(43.726, -79.417)`.

- **UTM Coordinates**: The XY coordinates are stored in UTM format, which can introduce precision errors when read directly in float format. To avoid precision issues, an offset `UTM_OFFSET = [627285, 4841948, 0]` is used to adjust the raw coordinates.
- **Potential Grid Subsampling Issues**: The dataset could face issues during grid subsampling (as seen with KPConv and RandLA-Net, where a grid size of 6 cm leads to data loss).

You can access the dataset on [Kaggle](https://www.kaggle.com/datasets/priteshraj10/point-cloud-lidar-toronto-3d/data).

## Model
This project implements **PointNet**, a pioneering deep learning architecture for point cloud data. The architecture is enhanced with a segmentation head to classify individual points into semantic classes, making it well-suited for urban road segmentation tasks.

- **Architecture**: PointNet processes each point independently using shared Multi-Layer Perceptrons (MLPs). A symmetric function (e.g., max pooling) aggregates local features to create a global feature vector, capturing the structure of the entire point cloud.
- **Input**: PointNet takes variable-sized point clouds as input, where each point is defined by its `(x, y, z)` coordinates.

For more on the architecture, refer to the original paper, ["PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"](https://arxiv.org/abs/1612.00593) (CVPR 2017) by Qi et al.

## Training Process

![lidar class labels](https://github.com/user-attachments/assets/7b1680dd-74a2-41d3-b323-9e9005442cf0)

The training process was performed on 3D point clouds of Toronto, utilizing several key techniques:

- **Data Augmentation**: Applied random rotations, Gaussian noise, and normalization to improve generalization.
- **Loss Function**: A custom loss function addresses class imbalance. Evaluation metrics such as IoU (Intersection over Union) and MCC (Matthews Correlation Coefficient) were used to assess performance.
- **Optimization**: The Adam optimizer was used with a learning rate of `X` (update with actual value).

## Results

![Lidar results](https://github.com/user-attachments/assets/afbb6e87-aee8-4464-ade0-85fda01dd689)

```bash
Epoch: 35
Train Loss: 0.1870  | Train Accuracy: 0.8903 | Train MCC: 0.8282 | Train IoU: 0.8048
Validation Loss: 0.1928 | Validation Accuracy: 0.8863 | Validation MCC: 0.8257 | Validation IoU: 0.8025


# Usage
To run the code locally, follow these steps:

**Clone the repository**:
  git clone https://github.com/your-repo/Point-Cloud-ML.git
**Install the required dependencies**:
  pip install -r requirements.txt
**Set up the dataset by downloading it from Kaggle and placing it in the appropriate directory.**
**Run the training script**:
  The notebook file
  
# Conclusion

![matrix lidar](https://github.com/user-attachments/assets/4ac1b84c-f6c5-4238-991a-c44c8ee20de9)

This project demonstrates the successful application of PointNet for urban point cloud segmentation. Future work includes exploring more advanced architectures such as KPConv or RandLA-Net for improved accuracy.
